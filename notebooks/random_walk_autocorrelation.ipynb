{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import collections\n",
    "import itertools\n",
    "import pickle\n",
    "from scipy.integrate import quad\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.special import logit, expit\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Walk Autocorrelation (RWA)\n",
    " - this notebook contains code to compute the random walk autocorrelation on NAS-Bench-201 datasets, and on arbitrary probability density functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the RWA from PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, define a few PDFs\n",
    "\n",
    "def sample(v, std=.35, dist='normal'):\n",
    "    # sample a random point from the nbhd of v\n",
    "    if dist == 'uniform':\n",
    "        return np.random.rand()\n",
    "    elif dist == 'lipschitz':\n",
    "        return np.random.uniform(max(0, v-std), min(1, v+std))\n",
    "    elif dist == 'normal':\n",
    "        # rejection sampling\n",
    "        u = np.random.rand()\n",
    "        y = np.random.rand() * pdf(v, v, dist='normal', std=std)\n",
    "        if y < pdf(u, v, dist='normal', std=std):\n",
    "            return u\n",
    "        else:\n",
    "            return sample(v, std=std, dist='lipschitz')\n",
    "        \n",
    "def pdf(u, v, dist='normal', std=.35):\n",
    "    # return the value of the pdf of nbhd(v) at u\n",
    "    if dist == 'uniform':\n",
    "        # uniform distribution on [0,1]\n",
    "        return 1\n",
    "    elif dist == 'lipschitz':\n",
    "        # uniform on [v-std, v+std]\n",
    "        if v - std <= u and u <= v + std:\n",
    "            return 1/(min(1, v+std)-max(0, v-std))\n",
    "        else: \n",
    "            return 0\n",
    "    elif dist == 'normal':\n",
    "        # normal dist with mean=v, std=std, scaled to be in [0,1]\n",
    "        return norm.pdf(u, v, std) * (norm.cdf(1, v, std) - norm.cdf(0, v, std)) ** -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_constrained(cell, std, low=0, high=1, dist='normal'):\n",
    "    for _ in range(200):\n",
    "        sampled = sample(cell, std=std, dist=dist)\n",
    "        if sampled > low and sampled < high:\n",
    "            return sampled\n",
    "    return cell\n",
    "\n",
    "def rwa_from_pdf(trials=100000,\n",
    "                size=36,\n",
    "                std=.35,\n",
    "                low=0,\n",
    "                high=1):\n",
    "    # compute RWA for a synthetic dataset based on a PDF\n",
    "    cell = .25\n",
    "    window = collections.deque([cell])\n",
    "    for _ in range(size - 1):\n",
    "        cell = sample_constrained(cell, std=std, low=low, high=high, dist='normal')\n",
    "        window.append(cell)\n",
    "    \n",
    "    autocorrs = np.zeros((size, trials, 2))\n",
    "    for t in range(trials):\n",
    "        if t % (trials/10) == 0:\n",
    "            print('trial', t)\n",
    "            #pass\n",
    "        cell = sample_constrained(cell, std=std, low=low, high=high, dist='normal')\n",
    "        window.append(cell)\n",
    "        window.popleft()\n",
    "        autocorrs[:, t, 0] = np.array([window[-1]] * size)\n",
    "        autocorrs[:, t, 1] = np.array(window)\n",
    "    \n",
    "    corr = []\n",
    "    for i in range(size):\n",
    "        corr.append(np.corrcoef(autocorrs[i, :, 0], autocorrs[i, :, 1])[1,0])\n",
    "    xs = [np.power(size - i - 1, 1/2) for i in range(size)]\n",
    "    return xs, corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute RWA on the NASBench-201 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.expanduser('~/naszilla/bananas'))\n",
    "sys.path.append(os.path.expanduser('~/AutoDL-Projects/lib/'))\n",
    "\n",
    "from nas_bench_201.cell import Cell\n",
    "from nas_201_api import NASBench201API as API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pert(cell, nasbench, low=0, high=100):\n",
    "    for i in range(200):\n",
    "        perturbed = Cell(**cell).perturb(nasbench)\n",
    "        if Cell(**perturbed).get_val_loss(nasbench, dataset=dataset) > low and \\\n",
    "        Cell(**perturbed).get_val_loss(nasbench, dataset=dataset) < high:\n",
    "            return perturbed\n",
    "    print('failed')\n",
    "    return Cell(**cell).perturb(nasbench)\n",
    "\n",
    "def random_walk(nasbench,\n",
    "                trials=10000,\n",
    "                size=36,\n",
    "                dataset='cifar10',\n",
    "                save=False,\n",
    "                low=0,\n",
    "                high=100):\n",
    "    \n",
    "    # if low, high are proportions, compute the losses\n",
    "    if high < 1:\n",
    "        losses, _ = pickle.load(open('{}_losses.pkl'.format(dataset), 'rb'))\n",
    "        losses.sort()\n",
    "        limits = [losses[0], losses[-1]]\n",
    "        low, high = [losses[int(low*15625)], losses[int(high*15625)]]\n",
    "        print('limits', limits)\n",
    "        print('scaled limits', low, high)\n",
    "        \n",
    "    # compute rwa for a dataset in nasbench-201\n",
    "    cell = Cell.random_cell(nasbench)\n",
    "    while Cell(**cell).get_val_loss(nasbench, dataset=dataset) < low or \\\n",
    "    Cell(**cell).get_val_loss(nasbench, dataset=dataset) > high:\n",
    "        cell = Cell.random_cell(nasbench)\n",
    "\n",
    "    window = collections.deque([cell])\n",
    "    for _ in range(size - 1):\n",
    "        cell = pert(cell, nasbench, low=low, high=high)\n",
    "        window.append(Cell(**cell).get_val_loss(nasbench, dataset=dataset))\n",
    "    \n",
    "    autocorrs = np.zeros((size, trials, 2))\n",
    "    for t in range(trials):\n",
    "        if t % (trials/10) == 0:\n",
    "            print('trial', t)\n",
    "\n",
    "        cell = pert(cell, nasbench, low=low, high=high)\n",
    "        window.append(Cell(**cell).get_val_loss(nasbench, dataset=dataset))\n",
    "        window.popleft()\n",
    "        autocorrs[:, t, 0] = np.array([window[-1]] * size)\n",
    "        autocorrs[:, t, 1] = np.array(window)\n",
    "    \n",
    "    corr = []\n",
    "    for i in range(size):\n",
    "        corr.append(np.corrcoef(autocorrs[i, :, 0], autocorrs[i, :, 1])[1,0])\n",
    "    xs = [np.power(size - i - 1, 1/2) for i in range(size)]\n",
    "    return xs, corr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data\n",
    "rwa_normals = {}\n",
    "for std in [.3, .35, .4]:\n",
    "    print('starting', std)\n",
    "    xs, corr = rwa_from_pdf(std=std, trials=10000)\n",
    "    rwa_normals[std] = corr \n",
    "    plt.plot(data['xs'], corr, label='normal pdf, std={}'.format(std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# download the nas-bench-201 dataset, and then load it with this command\n",
    "nasbench = API(os.path.expanduser('~/path/to/NAS-Bench-201-v1_0-e61699.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute RWA on the nas-bench-201 datasets\n",
    "datasets = ['ImageNet16-120', 'cifar100', 'cifar10']\n",
    "corrs = {}\n",
    "for dataset in datasets:\n",
    "    _, corr = random_walk(nasbench, dataset=dataset, save=False, trials=10000, low=.1, high=.9)\n",
    "    corrs[dataset] = corr\n",
    "    print('finished', dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
